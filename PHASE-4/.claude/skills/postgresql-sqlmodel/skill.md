# PostgreSQL + SQLModel Design & Management Skill

This skill scaffolds a robust PostgreSQL‑backed data layer using **SQLModel** (SQLAlchemy + Pydantic) and provides best‑practice patterns for:

- Table design and modeling
- Relationships (one‑to‑many, many‑to‑many, self‑referencing)
- Indexes and constraints
- Connection handling and pooling
- Migrations
- Query optimization and pagination
- Transactions and session management

---

## What the skill generates

When invoked, describe the tables you need and any special requirements (e.g., composite primary keys, many‑to‑many relationships, indexed columns). The skill will produce:

1. **Project layout**

   ```text
   pg-sqlmodel/
   ├─ app/
   │  ├─ db/
   │  │  ├─ models.py        # SQLModel table definitions with indexes/constraints
   │  │  ├─ session.py       # async session factory using asyncpg/psycopg
   │  │  └─ migrations/      # Alembic migration scripts
   │  ├─ core/
   │  │  └─ config.py        # Loads DB URL from .env via python‑dotenv
   │  └─ utils/
   │     └─ query.py         # Helper functions for optimized queries, pagination, eager loading
   └─ requirements.txt
   ```

2. **SQLModel table design patterns**

   - Primary keys (including UUID), composite keys, unique constraints, and indexes.
   - One‑to‑many, many‑to‑many, and self‑referencing relationships.
   - Foreign‑key constraints with `ondelete`/`onupdate` actions.
   - Base mixins, timestamp fields (`created_at`, `updated_at`), soft‑delete flag (`is_active`).
   - Composite indexes and unique constraints for business rules.

3. **Connection management**

   - Async engine (`create_async_engine` / `create_engine`) with `psycopg` or `asyncpg` driver.
   - Connection pool settings (e.g. `POOL_SIZE`, `MAX_OVERFLOW`) via environment variables.
   - Optional sync engine when needed.

4. **Session handling**

   - `AsyncSession` factory using SQLModel / SQLAlchemy.
   - Context‑manager‑style `get_session()` for FastAPI dependency injection or manual usage.
   - Transaction‑scoped sessions for atomic operations.

5. **Migrations**

   - Pre‑configured Alembic with:
     - `alembic.ini`
     - `env.py` wired to `SQLModel.metadata`
     - A `migrations/versions` folder for autogenerated scripts
   - Optional helper script `manage.py` to run:
     - `alembic revision --autogenerate`
     - `alembic upgrade head`

6. **Query optimization helpers**

   - Utilities for eager loading (`selectinload`, `joinedload`).
   - Column‑only loads for performance.
   - Pagination helpers.
   - `EXPLAIN ANALYZE` logging guidance.

7. **Best‑practice checklist**

   - Naming conventions and snake_case table/column names.
   - Using UUID primary keys when appropriate.
   - Avoiding nullable foreign keys when possible.
   - Indexing foreign key columns and frequently queried fields.
   - Limiting `SELECT *` and paginating large result sets.
   - Running Alembic autogenerate after every model change.
   - Wrapping multi‑step writes in transaction blocks.

---

## Usage example (prompt to the skill)

```text
Create User, Article, Comment tables. Users have many articles, articles have many comments.
Add a unique index on User.email, a composite index on (Article.author_id, Article.published_at),
and a foreign‑key cascade delete from Article to Comment.
```

The skill will output a ready‑to‑run project structure and example models.

---

## Sample generated files (excerpt)

### `app/core/config.py`

```python
from pathlib import Path
from dotenv import load_dotenv
import os

load_dotenv(Path('.') / '.env')

class Settings:
    DATABASE_URL: str = os.getenv(
        'DATABASE_URL',
        'postgresql+asyncpg://user:pass@localhost:5432/dbname',
    )
    # Connection pool settings (optional)
    POOL_SIZE: int = int(os.getenv('POOL_SIZE', '10'))
    MAX_OVERFLOW: int = int(os.getenv('MAX_OVERFLOW', '20'))
```

### `app/db/session.py`

```python
from sqlmodel.ext.asyncio.session import AsyncSession
from sqlalchemy.ext.asyncio import create_async_engine
from contextlib import asynccontextmanager
from app.core.config import Settings

engine = create_async_engine(Settings.DATABASE_URL, echo=False, future=True)

@asynccontextmanager
async def get_session() -> AsyncSession:
    async with AsyncSession(engine) as session:
        async with session.begin():
            yield session
```

### `app/db/models.py`

```python
from sqlmodel import SQLModel, Field, Relationship
from typing import List, Optional
from datetime import datetime
import uuid
from sqlalchemy import UniqueConstraint, Index

class TimestampMixin(SQLModel):
    created_at: datetime = Field(default_factory=datetime.utcnow, nullable=False)
    updated_at: datetime = Field(default_factory=datetime.utcnow, nullable=False)

class BaseUUIDModel(SQLModel):
    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True, index=True)

class User(BaseUUIDModel, TimestampMixin, table=True):
    __tablename__ = "users"
    email: str = Field(index=True, nullable=False, unique=True)
    hashed_password: str = Field(nullable=False)
    is_active: bool = Field(default=True)
    posts: List["Post"] = Relationship(back_populates="author")

class Post(BaseUUIDModel, TimestampMixin, table=True):
    __tablename__ = "posts"
    title: str = Field(index=True, nullable=False)
    body: str = Field(nullable=False)
    author_id: uuid.UUID = Field(
        foreign_key="users.id",
        nullable=False,
        index=True,
    )
    author: User = Relationship(back_populates="posts")
    # Composite unique index (author_id, title)
    __table_args__ = (
        UniqueConstraint("author_id", "title", name="uq_author_title"),
        Index("ix_posts_author_created_at", "author_id", "created_at"),
    )
```

### Alembic `env.py`

```python
from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
from sqlmodel import SQLModel
from app.db import models  # import all models so metadata is populated

config = context.config
fileConfig(config.config_file_name)

target_metadata = SQLModel.metadata

def run_migrations_online():
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata)
        with context.begin_transaction():
            context.run_migrations()

run_migrations_online()
```

### `manage.py` (migration helper)

```python
import subprocess
import sys

def alembic_cmd(*args):
    subprocess.run(['alembic'] + list(args), check=True)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print('Usage: manage.py <revision|upgrade|downgrade> [...]')
        sys.exit(1)
    command = sys.argv[1]
    alembic_cmd(command, *sys.argv[2:])
```

---

## How to use the skill

1. **Describe your schema**

   ```text
   Create a Customer table with UUID primary key, name, email (unique),
   and an Order table linked via foreign key. Include indexes on email
   and customer_id, and a many‑to‑many OrderItem association with Product.
   ```

2. **Install dependencies**

   ```bash
   pip install sqlmodel psycopg[binary] asyncpg alembic python-dotenv
   ```

3. **Create `.env`**

   ```bash
   echo "DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/dbname" > .env
   ```

4. **Initialize and run migrations**

   ```bash
   alembic revision --autogenerate -m "initial schema"
   alembic upgrade head
   # or via manage.py:
   # python manage.py revision --autogenerate -m "initial"
   # python manage.py upgrade head
   ```

5. **Use `get_session()`**

   - Inject `get_session()` into FastAPI routes or other async contexts.
   - Perform CRUD operations inside the provided transaction scope.

---

## Performance & Best Practices

- **Indexes**
  - Create after bulk inserts when possible.
  - Use partial indexes for filtered data.
  - Always index foreign key columns and frequently queried fields.

- **Connection pooling**
  - Let SQLAlchemy manage pooling.
  - Set `pool_size`, `max_overflow` via engine/create_async_engine if needed.

- **Batch inserts**
  - Use `session.add_all()` with `await session.commit()` inside a transaction.

- **Read‑only queries**
  - Use `session.execute(select(...).execution_options(populate_existing=True))`.
  - Limit selected columns where possible.

- **Avoid N+1**
  - Use `selectinload` or `joinedload` for eager loading of relationships.

- **Transactions**
  - Wrap multi‑step writes in `async with session.begin():` or a `run_in_transaction()` helper.

- **Testing**
  - Spin up a temporary PostgreSQL container:
    ```bash
    docker run -d -e POSTGRES_PASSWORD=pass -p 5432:5432 postgres
    ```
  - Point `DATABASE_URL` to this test instance.

---

**Note:** Adjust `requirements.txt` and `.env` values to match your deployment environment and preferred PostgreSQL driver (`psycopg2-binary`, `psycopg`, or `asyncpg`).
